{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b17c259-af8b-418d-9426-3d23420cb8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from my_snn.tonic_dataloader import DatasetLoader\n",
    "from my_snn.abstract_rsnn import CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291db3c7-2bcd-4032-9032-e6bb6880a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'shd'\n",
    "time_window = 250\n",
    "batch_size = 64 # lr=1e-4\n",
    "#batch_size = 128 # lr=1e-4\n",
    "DL = DatasetLoader(dataset=dataset, caching='memory', num_workers=0, batch_size=batch_size, time_window=time_window)\n",
    "test_loader, train_loader = DL.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff38f38d-249f-4308-81e2-e1b4a4f6b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_type:  MG\n",
      "hight:  0.15 ;scale:  6.0\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import os\n",
    "\n",
    "torch.manual_seed(2)\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "decay = 0.1  # neuron decay rate\n",
    "thresh = 0.5  # neuronal threshold\n",
    "lens = 0.5  # hyper-parameters of approximate function\n",
    "num_epochs = 20  # 150  # n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "'''\n",
    "STEP 3a: CREATE spike MODEL CLASS\n",
    "'''\n",
    "\n",
    "b_j0 = 0.01  # neural threshold baseline\n",
    "R_m = 1  # membrane resistance\n",
    "dt = 1  #\n",
    "gamma = .5  # gradient scale\n",
    "\n",
    "# define approximate firing function\n",
    "\n",
    "gradient_type = 'MG'\n",
    "print('gradient_type: ',gradient_type)\n",
    "scale = 6.\n",
    "hight = 0.15\n",
    "print('hight: ',hight,';scale: ',scale)\n",
    "\n",
    "def gaussian(x, mu=0., sigma=.5):\n",
    "    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(math.pi)) / sigma\n",
    "\n",
    "\n",
    "# define approximate firing function\n",
    "\n",
    "class ActFun_adp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):  # input = membrane potential- threshold\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(0).float()  # is firing ???\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # approximate the gradients\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        # temp = abs(input) < lens\n",
    "  \n",
    "        if gradient_type == 'G':\n",
    "            temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(math.pi))/lens\n",
    "        elif gradient_type == 'MG':\n",
    "            temp = gaussian(input, mu=0., sigma=lens) * (1. + hight) \\\n",
    "                - gaussian(input, mu=lens, sigma=scale * lens) * hight \\\n",
    "                - gaussian(input, mu=-lens, sigma=scale * lens) * hight\n",
    "        elif gradient_type =='linear':\n",
    "            temp = F.relu(1-input.abs())\n",
    "        elif gradient_type == 'slayer':\n",
    "            temp = torch.exp(-5*input.abs())\n",
    "        return grad_input * temp.float() * gamma\n",
    "\n",
    "act_fun_adp = ActFun_adp.apply\n",
    "# tau_m = torch.FloatTensor([tau_m])\n",
    "\n",
    "def mem_update_adp(inputs, mem, spike, tau_adp, b, tau_m, dt=1, isAdapt=1):\n",
    "    alpha = torch.exp(-1. * dt / tau_m).cuda()\n",
    "    ro = torch.exp(-1. * dt / tau_adp).cuda()\n",
    "    if isAdapt:\n",
    "        beta = 1.8\n",
    "    else:\n",
    "        beta = 0.\n",
    "\n",
    "    b = ro * b + (1 - ro) * spike\n",
    "    B = b_j0 + beta * b\n",
    "    mem = mem * alpha + (1 - alpha) * R_m * inputs - B * spike * dt\n",
    "    \n",
    "    inputs_ = mem - B\n",
    "    spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
    "    return mem, spike, B, b\n",
    "\n",
    "\n",
    "def output_Neuron(inputs, mem, tau_m, dt=1):\n",
    "    \"\"\"\n",
    "    The read out neuron is leaky integrator without spike\n",
    "    \"\"\"\n",
    "    # alpha = torch.exp(-1. * dt / torch.FloatTensor([30.])).cuda()\n",
    "    alpha = torch.exp(-1. * dt / tau_m).cuda()\n",
    "    mem = mem * alpha + (1. - alpha) * R_m * inputs\n",
    "    return mem\n",
    "\n",
    "\n",
    "class RNN_custom(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_custom, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.hidden_size = input_size\n",
    "        self.i_2_h1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.h1_2_h1 = nn.Linear(hidden_size[0], hidden_size[0])\n",
    "        self.h1_2_h2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.h2_2_h2 = nn.Linear(hidden_size[1], hidden_size[1])\n",
    "\n",
    "        self.h2o = nn.Linear(hidden_size[1], output_size)\n",
    "\n",
    "        self.tau_adp_h1 = nn.Parameter(torch.Tensor(hidden_size[0]))\n",
    "        self.tau_adp_h2 = nn.Parameter(torch.Tensor(hidden_size[1]))\n",
    "        self.tau_adp_o = nn.Parameter(torch.Tensor(output_size))\n",
    "        self.tau_m_h1 = nn.Parameter(torch.Tensor(hidden_size[0]))\n",
    "        self.tau_m_h2 = nn.Parameter(torch.Tensor(hidden_size[1]))\n",
    "        self.tau_m_o = nn.Parameter(torch.Tensor(output_size))\n",
    "\n",
    "        # nn.init.orthogonal_(self.h1_2_h1.weight)\n",
    "        # nn.init.orthogonal_(self.h2_2_h2.weight)\n",
    "        nn.init.orthogonal_(self.h1_2_h1.weight)\n",
    "        nn.init.orthogonal_(self.h2_2_h2.weight)\n",
    "        nn.init.xavier_uniform_(self.i_2_h1.weight)\n",
    "        nn.init.xavier_uniform_(self.h1_2_h2.weight)\n",
    "        nn.init.xavier_uniform_(self.h2o.weight)\n",
    "\n",
    "        nn.init.constant_(self.i_2_h1.bias, 0)\n",
    "        nn.init.constant_(self.h1_2_h2.bias, 0)\n",
    "        nn.init.constant_(self.h2_2_h2.bias, 0)\n",
    "        nn.init.constant_(self.h1_2_h1.bias, 0)\n",
    "\n",
    "        nn.init.normal_(self.tau_adp_h1,150,10)\n",
    "        nn.init.normal_(self.tau_adp_h2, 150,10)\n",
    "        nn.init.normal_(self.tau_adp_o, 150,10)\n",
    "        nn.init.normal_(self.tau_m_h1, 20.,5)\n",
    "        nn.init.normal_(self.tau_m_h2, 20.,5)\n",
    "        nn.init.normal_(self.tau_m_o, 20.,5)\n",
    "\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "\n",
    "        self.b_h1 = self.b_h2 = self.b_o = 0\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size, seq_num, input_dim = input.shape\n",
    "        self.b_h1 = self.b_h2 = self.b_o = b_j0\n",
    "        # mem_layer1 = spike_layer1 = torch.zeros(batch_size, self.hidden_size[0]).cuda()\n",
    "        # mem_layer2 = spike_layer2 = torch.zeros(batch_size, self.hidden_size[1]).cuda()\n",
    "        mem_layer1 = torch.rand(batch_size, self.hidden_size[0]).cuda()\n",
    "        mem_layer2 = torch.rand(batch_size, self.hidden_size[1]).cuda()\n",
    "\n",
    "        spike_layer1 = torch.zeros(batch_size, self.hidden_size[0]).cuda()\n",
    "        spike_layer2 = torch.zeros(batch_size, self.hidden_size[1]).cuda()\n",
    "        mem_output = torch.rand(batch_size, output_dim).cuda()\n",
    "        output = torch.zeros(batch_size, output_dim).cuda()\n",
    "\n",
    "        hidden_spike_ = []\n",
    "        hidden_mem_ = []\n",
    "        h2o_mem_ = []\n",
    "\n",
    "        for i in range(seq_num):\n",
    "            input_x = input[:, i, :]\n",
    "\n",
    "            h_input = self.i_2_h1(input_x.float()) + self.h1_2_h1(spike_layer1)\n",
    "            mem_layer1, spike_layer1, theta_h1, self.b_h1 = mem_update_adp(h_input, mem_layer1, spike_layer1,\n",
    "                                                                         self.tau_adp_h1, self.b_h1,self.tau_m_h1)\n",
    "            # spike_layer1 = self.dp(spike_layer1)\n",
    "            h2_input = self.h1_2_h2(spike_layer1) + self.h2_2_h2(spike_layer2)\n",
    "            mem_layer2, spike_layer2, theta_h2, self.b_h2 = mem_update_adp(h2_input, mem_layer2, spike_layer2,\n",
    "                                                                         self.tau_adp_h2, self.b_h2, self.tau_m_h2)\n",
    "            mem_output = output_Neuron(self.h2o(spike_layer2), mem_output, self.tau_m_o)\n",
    "            if i > 10:\n",
    "                output= output + F.softmax(mem_output, dim=1)#F.softmax(mem_output, dim=1)#\n",
    "\n",
    "            hidden_spike_.append(spike_layer1.data.cpu().numpy())\n",
    "            hidden_mem_.append(mem_layer1.data.cpu().numpy())\n",
    "            h2o_mem_.append(mem_output.data.cpu().numpy())\n",
    "\n",
    "        return output, hidden_spike_, hidden_mem_, h2o_mem_\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [128,128]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "def train(model, num_epochs=150):\n",
    "    acc = []\n",
    "    best_accuracy = 80\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(1,num_epochs):\n",
    "        loss_sum = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            #images = images.view(-1, seq_dim, input_dim).requires_grad_().to(device)\n",
    "            images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            labels = labels.long().to(device)\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass to get output/logits\n",
    "            outputs, _,_,_ = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sum+= loss\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            if torch.cuda.is_available():\n",
    "                correct += (predicted.cpu() == labels.long().cpu()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        scheduler.step()\n",
    "        accuracy = 100. * correct.numpy() / total\n",
    "        # accuracy,_ = test(model, train_loader)\n",
    "        ts_acc,fr = test(model,is_test=0)\n",
    "        if ts_acc > best_accuracy and accuracy > 80:\n",
    "            torch.save(model, path+'/rsnn{}_alif_new_epoch{}.pth'.format(hidden_dim[0], epoch))\n",
    "            best_accuracy = ts_acc\n",
    " \n",
    "        print('epoch: ', epoch, '. Loss: ', loss.item(), '. Tr Accuracy: ', accuracy, '. Ts Accuracy: ',\n",
    "         ts_acc, 'Fr: ',fr)\n",
    "\n",
    "        acc.append(accuracy)\n",
    "        # if epoch %5==0:\n",
    "        #     print('epoch: ', epoch, '. Loss: ', loss_sum.item()/i, \n",
    "        #             '. Tr Accuracy: ', accuracy, '. Ts Accuracy: ', ts_acc,', Fr: ',fr)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def test(model, dataloader=test_loader,is_test=0):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in dataloader:\n",
    "        images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "        _, labels = torch.max(labels.data, 1)\n",
    "\n",
    "        outputs, fr_,_,_ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        if torch.cuda.is_available():\n",
    "            correct += (predicted.cpu() == labels.long().cpu()).sum()\n",
    "        else:\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100. * correct.numpy() / total\n",
    "    if is_test:\n",
    "        print('Mean FR: ', np.array(fr_).mean())\n",
    "    return accuracy, np.array(fr_).mean()\n",
    "\n",
    "# dataset shape:  (8156, 250, 700)\n",
    "# dataset shape:  (2264, 250, 700)\n",
    "# gradient_type:  MG\n",
    "# hight:  0.15 ;scale:  6.0\n",
    "# device: cuda:0\n",
    "# epoch:  1 . Loss:  1.4047224521636963 . Tr Accuracy:  30.946542422756252 . Ts Accuracy:  40.90106007067138 Fr:  0.10361849\n",
    "# epoch:  2 . Loss:  0.5009759664535522 . Tr Accuracy:  58.26385483079941 . Ts Accuracy:  75.79505300353357 Fr:  0.14015365\n",
    "# epoch:  3 . Loss:  0.8235954642295837 . Tr Accuracy:  80.44384502206964 . Ts Accuracy:  86.17491166077738 Fr:  0.12855339\n",
    "# epoch:  4 . Loss:  0.1801595240831375 . Tr Accuracy:  85.93673369298676 . Ts Accuracy:  78.00353356890459 Fr:  0.12772396\n",
    "# epoch:  5 . Loss:  0.6335716843605042 . Tr Accuracy:  87.84943599803826 . Ts Accuracy:  83.25971731448763 Fr:  0.122699216\n",
    "# epoch:  6 . Loss:  0.4184652864933014 . Tr Accuracy:  88.46248160863168 . Ts Accuracy:  85.02650176678445 Fr:  0.12641016\n",
    "# epoch:  7 . Loss:  0.11178665608167648 . Tr Accuracy:  91.66257969592938 . Ts Accuracy:  83.70141342756183 Fr:  0.11583985\n",
    "# epoch:  8 . Loss:  0.24507765471935272 . Tr Accuracy:  93.80823933300637 . Ts Accuracy:  80.43286219081273 Fr:  0.11689453\n",
    "# epoch:  9 . Loss:  0.02580219879746437 . Tr Accuracy:  93.6856302108877 . Ts Accuracy:  78.53356890459364 Fr:  0.11530859\n",
    "# epoch:  10 . Loss:  0.132295161485672 . Tr Accuracy:  95.15693967631192 . Ts Accuracy:  87.0583038869258 Fr:  0.107161455\n",
    "# epoch:  11 . Loss:  0.052720583975315094 . Tr Accuracy:  97.4619911721432 . Ts Accuracy:  87.54416961130742 Fr:  0.111710936\n",
    "# epoch:  12 . Loss:  0.013912809081375599 . Tr Accuracy:  97.63364394310936 . Ts Accuracy:  88.29505300353357 Fr:  0.11046224\n",
    "# epoch:  13 . Loss:  0.013542967848479748 . Tr Accuracy:  98.43060323688083 . Ts Accuracy:  84.31978798586573 Fr:  0.11176432\n",
    "# epoch:  14 . Loss:  0.03696903958916664 . Tr Accuracy:  98.14860225600785 . Ts Accuracy:  85.95406360424029 Fr:  0.113291666\n",
    "# epoch:  15 . Loss:  0.12882192432880402 . Tr Accuracy:  98.4428641490927 . Ts Accuracy:  84.67314487632508 Fr:  0.11321094\n",
    "# epoch:  16 . Loss:  0.008622714318335056 . Tr Accuracy:  98.60225600784699 . Ts Accuracy:  87.72084805653711 Fr:  0.11448698\n",
    "# epoch:  17 . Loss:  0.08007299154996872 . Tr Accuracy:  98.58999509563512 . Ts Accuracy:  85.07067137809187 Fr:  0.109397136\n",
    "# epoch:  18 . Loss:  0.17344336211681366 . Tr Accuracy:  97.91564492398234 . Ts Accuracy:  86.43992932862191 Fr:  0.114264324\n",
    "# epoch:  19 . Loss:  0.31412410736083984 . Tr Accuracy:  97.89112309955861 . Ts Accuracy:  90.68021201413427 Fr:  0.110308595\n",
    "# Mean FR:  0.10995052\n",
    "#  Accuracy:  90.7243816254417\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cff4229-de6c-4831-9501-ac5538b9ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [128,128]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb0fa89-58ea-45b0-b053-beaee617e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.1417795419692993 . Tr Accuracy:  28.506397637795274 . Ts Accuracy:  61.42857142857143 Fr:  0.12849511\n",
      "epoch:  2 . Loss:  0.5131941437721252 . Tr Accuracy:  67.39665354330708 . Ts Accuracy:  71.96428571428571 Fr:  0.119453125\n",
      "epoch:  3 . Loss:  0.44096359610557556 . Tr Accuracy:  82.45570866141732 . Ts Accuracy:  75.71428571428571 Fr:  0.11837598\n",
      "epoch:  4 . Loss:  0.16837456822395325 . Tr Accuracy:  89.0009842519685 . Ts Accuracy:  81.33928571428571 Fr:  0.11596582\n",
      "epoch:  5 . Loss:  0.27148526906967163 . Tr Accuracy:  92.00295275590551 . Ts Accuracy:  74.0625 Fr:  0.115331054\n",
      "epoch:  6 . Loss:  0.2539396286010742 . Tr Accuracy:  94.04527559055119 . Ts Accuracy:  77.99107142857143 Fr:  0.12006006\n",
      "epoch:  7 . Loss:  0.17388473451137543 . Tr Accuracy:  93.31938976377953 . Ts Accuracy:  82.54464285714286 Fr:  0.11574658\n",
      "epoch:  8 . Loss:  0.20907920598983765 . Tr Accuracy:  95.76771653543307 . Ts Accuracy:  84.73214285714286 Fr:  0.11130713\n",
      "epoch:  9 . Loss:  0.14359787106513977 . Tr Accuracy:  96.16141732283465 . Ts Accuracy:  84.01785714285714 Fr:  0.118461914\n",
      "epoch:  10 . Loss:  0.17541015148162842 . Tr Accuracy:  96.61663385826772 . Ts Accuracy:  82.41071428571429 Fr:  0.11341016\n",
      "epoch:  11 . Loss:  0.05613832175731659 . Tr Accuracy:  98.16683070866142 . Ts Accuracy:  81.83035714285714 Fr:  0.11322949\n",
      "epoch:  12 . Loss:  0.006123104598373175 . Tr Accuracy:  98.83120078740157 . Ts Accuracy:  81.42857142857143 Fr:  0.115023926\n",
      "epoch:  13 . Loss:  0.013703674077987671 . Tr Accuracy:  98.94192913385827 . Ts Accuracy:  85.08928571428571 Fr:  0.11230957\n",
      "epoch:  14 . Loss:  0.0352167934179306 . Tr Accuracy:  99.49557086614173 . Ts Accuracy:  84.33035714285714 Fr:  0.1129624\n",
      "epoch:  15 . Loss:  0.004467457067221403 . Tr Accuracy:  99.50787401574803 . Ts Accuracy:  86.74107142857143 Fr:  0.113728516\n",
      "epoch:  16 . Loss:  0.0180768184363842 . Tr Accuracy:  99.38484251968504 . Ts Accuracy:  84.86607142857143 Fr:  0.114983395\n",
      "epoch:  17 . Loss:  0.10037481039762497 . Tr Accuracy:  98.65895669291339 . Ts Accuracy:  82.00892857142857 Fr:  0.11505127\n",
      "epoch:  18 . Loss:  0.018264243379235268 . Tr Accuracy:  98.26525590551181 . Ts Accuracy:  81.20535714285714 Fr:  0.11379932\n",
      "epoch:  19 . Loss:  0.01692068763077259 . Tr Accuracy:  98.81889763779527 . Ts Accuracy:  81.60714285714286 Fr:  0.11694189\n",
      "Mean FR:  0.11566699\n",
      " Accuracy:  82.27678571428571\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7e05d29-eb7b-46d3-ab72-d9306b16b639",
   "metadata": {},
   "source": [
    "### images>0, dropout 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1e7166-1c80-4a0a-816c-7cbf3c84a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.2821640968322754 . Tr Accuracy:  26.85777559055118 . Ts Accuracy:  66.38392857142857 Fr:  0.12793213\n",
      "epoch:  2 . Loss:  0.4739812910556793 . Tr Accuracy:  70.3125 . Ts Accuracy:  75.3125 Fr:  0.116929196\n",
      "epoch:  3 . Loss:  0.42120224237442017 . Tr Accuracy:  83.14468503937007 . Ts Accuracy:  79.91071428571429 Fr:  0.12220996\n",
      "epoch:  4 . Loss:  0.26949840784072876 . Tr Accuracy:  87.37696850393701 . Ts Accuracy:  82.99107142857143 Fr:  0.12340674\n",
      "epoch:  5 . Loss:  0.08047826588153839 . Tr Accuracy:  91.21555118110236 . Ts Accuracy:  80.44642857142857 Fr:  0.120833986\n",
      "epoch:  6 . Loss:  0.2110244631767273 . Tr Accuracy:  91.96604330708661 . Ts Accuracy:  84.59821428571429 Fr:  0.1158706\n",
      "epoch:  7 . Loss:  0.17956425249576569 . Tr Accuracy:  93.97145669291339 . Ts Accuracy:  82.58928571428571 Fr:  0.120810546\n",
      "epoch:  8 . Loss:  0.15149128437042236 . Tr Accuracy:  93.9099409448819 . Ts Accuracy:  76.875 Fr:  0.11675781\n",
      "epoch:  9 . Loss:  0.10481612384319305 . Tr Accuracy:  94.82037401574803 . Ts Accuracy:  85.53571428571429 Fr:  0.11243555\n",
      "epoch:  10 . Loss:  0.18330912292003632 . Tr Accuracy:  95.75541338582677 . Ts Accuracy:  84.59821428571429 Fr:  0.114421874\n",
      "epoch:  11 . Loss:  0.09728700667619705 . Tr Accuracy:  98.03149606299213 . Ts Accuracy:  83.34821428571429 Fr:  0.11709375\n",
      "epoch:  12 . Loss:  0.1792808324098587 . Tr Accuracy:  98.63435039370079 . Ts Accuracy:  86.78571428571429 Fr:  0.119287595\n",
      "epoch:  13 . Loss:  0.05755675211548805 . Tr Accuracy:  98.62204724409449 . Ts Accuracy:  84.77678571428571 Fr:  0.11654199\n",
      "epoch:  14 . Loss:  0.011925937607884407 . Tr Accuracy:  98.69586614173228 . Ts Accuracy:  84.375 Fr:  0.11521338\n",
      "epoch:  15 . Loss:  0.036992255598306656 . Tr Accuracy:  98.68356299212599 . Ts Accuracy:  87.09821428571429 Fr:  0.11737353\n",
      "epoch:  16 . Loss:  0.07556798309087753 . Tr Accuracy:  98.51131889763779 . Ts Accuracy:  87.41071428571429 Fr:  0.117288575\n",
      "epoch:  17 . Loss:  0.020923631265759468 . Tr Accuracy:  98.83120078740157 . Ts Accuracy:  79.59821428571429 Fr:  0.11161377\n",
      "epoch:  18 . Loss:  0.0511050708591938 . Tr Accuracy:  98.79429133858268 . Ts Accuracy:  87.41071428571429 Fr:  0.11923584\n",
      "epoch:  19 . Loss:  0.031002666801214218 . Tr Accuracy:  99.01574803149606 . Ts Accuracy:  84.59821428571429 Fr:  0.11850293\n",
      "Mean FR:  0.11887696\n",
      " Accuracy:  84.59821428571429\n"
     ]
    }
   ],
   "source": [
    "dropout = torch.nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "def train(model, num_epochs=150):\n",
    "    acc = []\n",
    "    best_accuracy = 80\n",
    "    \n",
    "    for epoch in range(1,num_epochs):\n",
    "        loss_sum = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            #images = images.view(-1, seq_dim, input_dim).requires_grad_().to(device)\n",
    "\n",
    "            images = dropout(images.float())\n",
    "            images = images > 0            \n",
    "            \n",
    "            images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            labels = labels.long().to(device)\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass to get output/logits\n",
    "            outputs, _,_,_ = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sum+= loss\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            if torch.cuda.is_available():\n",
    "                correct += (predicted.cpu() == labels.long().cpu()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        scheduler.step()\n",
    "        accuracy = 100. * correct.numpy() / total\n",
    "        # accuracy,_ = test(model, train_loader)\n",
    "        ts_acc,fr = test(model,is_test=0)\n",
    "        if ts_acc > best_accuracy and accuracy > 80:\n",
    "            torch.save(model, path+'/rsnn{}_alif_new_epoch{}.pth'.format(hidden_dim[0], epoch))\n",
    "            best_accuracy = ts_acc\n",
    " \n",
    "        print('epoch: ', epoch, '. Loss: ', loss.item(), '. Tr Accuracy: ', accuracy, '. Ts Accuracy: ',\n",
    "         ts_acc, 'Fr: ',fr)\n",
    "\n",
    "        acc.append(accuracy)\n",
    "        # if epoch %5==0:\n",
    "        #     print('epoch: ', epoch, '. Loss: ', loss_sum.item()/i, \n",
    "        #             '. Tr Accuracy: ', accuracy, '. Ts Accuracy: ', ts_acc,', Fr: ',fr)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def test(model, dataloader=test_loader,is_test=0):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in dataloader:\n",
    "        \n",
    "        images = dropout(images.float())\n",
    "        images = images > 0    \n",
    "        \n",
    "        images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "        _, labels = torch.max(labels.data, 1)\n",
    "\n",
    "        outputs, fr_,_,_ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        if torch.cuda.is_available():\n",
    "            correct += (predicted.cpu() == labels.long().cpu()).sum()\n",
    "        else:\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100. * correct.numpy() / total\n",
    "    if is_test:\n",
    "        print('Mean FR: ', np.array(fr_).mean())\n",
    "    return accuracy, np.array(fr_).mean()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [128,128]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ec957b-bf65-482b-85bb-e02a83993f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.0533266067504883 . Tr Accuracy:  28.59251968503937 . Ts Accuracy:  61.07142857142857 Fr:  0.13657813\n",
      "epoch:  2 . Loss:  0.6155337691307068 . Tr Accuracy:  69.91879921259843 . Ts Accuracy:  71.69642857142857 Fr:  0.13449512\n",
      "epoch:  3 . Loss:  0.7312968969345093 . Tr Accuracy:  81.2992125984252 . Ts Accuracy:  75.22321428571429 Fr:  0.12997754\n",
      "epoch:  4 . Loss:  0.40226882696151733 . Tr Accuracy:  87.09399606299213 . Ts Accuracy:  78.21428571428571 Fr:  0.1302876\n",
      "epoch:  5 . Loss:  0.0942985787987709 . Tr Accuracy:  89.18553149606299 . Ts Accuracy:  80.08928571428571 Fr:  0.123591796\n",
      "epoch:  6 . Loss:  0.2178582102060318 . Tr Accuracy:  92.0275590551181 . Ts Accuracy:  84.77678571428571 Fr:  0.12568799\n",
      "epoch:  7 . Loss:  0.13728997111320496 . Tr Accuracy:  94.41437007874016 . Ts Accuracy:  82.23214285714286 Fr:  0.11818018\n",
      "epoch:  8 . Loss:  0.04252934083342552 . Tr Accuracy:  94.73425196850394 . Ts Accuracy:  85.84821428571429 Fr:  0.12506787\n",
      "epoch:  9 . Loss:  0.03214843571186066 . Tr Accuracy:  95.52165354330708 . Ts Accuracy:  86.38392857142857 Fr:  0.12515186\n",
      "epoch:  10 . Loss:  0.14461302757263184 . Tr Accuracy:  96.12450787401575 . Ts Accuracy:  81.25 Fr:  0.11934326\n",
      "epoch:  11 . Loss:  0.14834408462047577 . Tr Accuracy:  98.4251968503937 . Ts Accuracy:  82.94642857142857 Fr:  0.11703125\n",
      "epoch:  12 . Loss:  0.054041944444179535 . Tr Accuracy:  98.78198818897638 . Ts Accuracy:  84.82142857142857 Fr:  0.116865724\n",
      "epoch:  13 . Loss:  0.02603662759065628 . Tr Accuracy:  99.00344488188976 . Ts Accuracy:  84.19642857142857 Fr:  0.11695361\n",
      "epoch:  14 . Loss:  0.06249457225203514 . Tr Accuracy:  99.11417322834646 . Ts Accuracy:  84.0625 Fr:  0.119571775\n",
      "epoch:  15 . Loss:  0.021833909675478935 . Tr Accuracy:  98.90501968503936 . Ts Accuracy:  83.92857142857143 Fr:  0.12213965\n",
      "epoch:  16 . Loss:  0.015759281814098358 . Tr Accuracy:  98.26525590551181 . Ts Accuracy:  81.51785714285714 Fr:  0.11653369\n",
      "epoch:  17 . Loss:  0.018150635063648224 . Tr Accuracy:  98.01919291338582 . Ts Accuracy:  83.70535714285714 Fr:  0.11782422\n",
      "epoch:  18 . Loss:  0.008038564585149288 . Tr Accuracy:  98.73277559055119 . Ts Accuracy:  86.02678571428571 Fr:  0.11436914\n",
      "epoch:  19 . Loss:  0.04849658161401749 . Tr Accuracy:  98.62204724409449 . Ts Accuracy:  84.46428571428571 Fr:  0.11788476\n",
      "Mean FR:  0.11907666\n",
      " Accuracy:  84.64285714285714\n"
     ]
    }
   ],
   "source": [
    "dropout = torch.nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "def train(model, num_epochs=150):\n",
    "    acc = []\n",
    "    best_accuracy = 80\n",
    "    \n",
    "    for epoch in range(1,num_epochs):\n",
    "        loss_sum = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            #images = images.view(-1, seq_dim, input_dim).requires_grad_().to(device)\n",
    "\n",
    "            images = dropout(images.float())\n",
    "            images = images > 0            \n",
    "            \n",
    "            images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            labels = labels.long().to(device)\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass to get output/logits\n",
    "            outputs, _,_,_ = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sum+= loss\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            if torch.cuda.is_available():\n",
    "                correct += (predicted.cpu() == labels.long().cpu()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        scheduler.step()\n",
    "        accuracy = 100. * correct.numpy() / total\n",
    "        # accuracy,_ = test(model, train_loader)\n",
    "        ts_acc,fr = test(model,is_test=0)\n",
    "        if ts_acc > best_accuracy and accuracy > 80:\n",
    "            torch.save(model, path+'/rsnn{}_alif_new_epoch{}.pth'.format(hidden_dim[0], epoch))\n",
    "            best_accuracy = ts_acc\n",
    " \n",
    "        print('epoch: ', epoch, '. Loss: ', loss.item(), '. Tr Accuracy: ', accuracy, '. Ts Accuracy: ',\n",
    "         ts_acc, 'Fr: ',fr)\n",
    "\n",
    "        acc.append(accuracy)\n",
    "        # if epoch %5==0:\n",
    "        #     print('epoch: ', epoch, '. Loss: ', loss_sum.item()/i, \n",
    "        #             '. Tr Accuracy: ', accuracy, '. Ts Accuracy: ', ts_acc,', Fr: ',fr)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def test(model, dataloader=test_loader,is_test=0):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in dataloader:\n",
    "        \n",
    "        images = dropout(images.float())\n",
    "        images = images > 0    \n",
    "        \n",
    "        images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "        _, labels = torch.max(labels.data, 1)\n",
    "\n",
    "        outputs, fr_,_,_ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        if torch.cuda.is_available():\n",
    "            correct += (predicted.cpu() == labels.long().cpu()).sum()\n",
    "        else:\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100. * correct.numpy() / total\n",
    "    if is_test:\n",
    "        print('Mean FR: ', np.array(fr_).mean())\n",
    "    return accuracy, np.array(fr_).mean()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [128,128]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c517055-6106-4a62-84c3-e3a63e55e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.6024893522262573 . Tr Accuracy:  21.24753937007874 . Ts Accuracy:  49.642857142857146 Fr:  0.14380664\n",
      "epoch:  2 . Loss:  1.101971983909607 . Tr Accuracy:  57.04970472440945 . Ts Accuracy:  67.5 Fr:  0.16943066\n",
      "epoch:  3 . Loss:  0.7828410267829895 . Tr Accuracy:  75.49212598425197 . Ts Accuracy:  72.99107142857143 Fr:  0.16090918\n",
      "epoch:  4 . Loss:  0.4361381530761719 . Tr Accuracy:  83.23080708661418 . Ts Accuracy:  74.64285714285714 Fr:  0.16295801\n",
      "epoch:  5 . Loss:  0.4594704806804657 . Tr Accuracy:  88.16437007874016 . Ts Accuracy:  80.49107142857143 Fr:  0.16607226\n",
      "epoch:  6 . Loss:  0.6766268610954285 . Tr Accuracy:  91.64616141732283 . Ts Accuracy:  79.15178571428571 Fr:  0.16194433\n",
      "epoch:  7 . Loss:  0.4412130117416382 . Tr Accuracy:  92.61811023622047 . Ts Accuracy:  84.41964285714286 Fr:  0.15918067\n",
      "epoch:  8 . Loss:  0.26646819710731506 . Tr Accuracy:  93.27017716535433 . Ts Accuracy:  81.5625 Fr:  0.16016406\n",
      "epoch:  9 . Loss:  0.14215530455112457 . Tr Accuracy:  94.74655511811024 . Ts Accuracy:  77.05357142857143 Fr:  0.16201074\n",
      "epoch:  10 . Loss:  0.3591414988040924 . Tr Accuracy:  94.66043307086615 . Ts Accuracy:  81.20535714285714 Fr:  0.1537705\n",
      "epoch:  11 . Loss:  0.06498511880636215 . Tr Accuracy:  97.01033464566929 . Ts Accuracy:  82.94642857142857 Fr:  0.15829296\n",
      "epoch:  12 . Loss:  0.06168957054615021 . Tr Accuracy:  97.56397637795276 . Ts Accuracy:  82.54464285714286 Fr:  0.1601504\n",
      "epoch:  13 . Loss:  0.04058458283543587 . Tr Accuracy:  97.71161417322834 . Ts Accuracy:  85.04464285714286 Fr:  0.16219921\n",
      "epoch:  14 . Loss:  0.03731188550591469 . Tr Accuracy:  97.98228346456693 . Ts Accuracy:  82.58928571428571 Fr:  0.15978515\n",
      "epoch:  15 . Loss:  0.02954566478729248 . Tr Accuracy:  98.11761811023622 . Ts Accuracy:  81.96428571428571 Fr:  0.16297852\n",
      "epoch:  16 . Loss:  0.028123648837208748 . Tr Accuracy:  97.88385826771653 . Ts Accuracy:  82.94642857142857 Fr:  0.16414258\n",
      "epoch:  17 . Loss:  0.013692239299416542 . Tr Accuracy:  98.05610236220473 . Ts Accuracy:  83.08035714285714 Fr:  0.16061719\n",
      "epoch:  18 . Loss:  0.09871242940425873 . Tr Accuracy:  98.4005905511811 . Ts Accuracy:  82.23214285714286 Fr:  0.164125\n",
      "epoch:  19 . Loss:  0.034638598561286926 . Tr Accuracy:  98.28986220472441 . Ts Accuracy:  80.26785714285714 Fr:  0.1628252\n",
      "Mean FR:  0.16206934\n",
      " Accuracy:  80.71428571428571\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [64,64]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7994b7c3-70f3-4f48-9bd2-c8dedbe571b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.7800135612487793 . Tr Accuracy:  17.753444881889763 . Ts Accuracy:  36.294642857142854 Fr:  0.15179297\n",
      "epoch:  2 . Loss:  0.7516031861305237 . Tr Accuracy:  58.87057086614173 . Ts Accuracy:  68.83928571428571 Fr:  0.16226692\n",
      "epoch:  3 . Loss:  0.5555938482284546 . Tr Accuracy:  75.99655511811024 . Ts Accuracy:  77.72321428571429 Fr:  0.16349609\n",
      "epoch:  4 . Loss:  0.3401418924331665 . Tr Accuracy:  82.8248031496063 . Ts Accuracy:  73.52678571428571 Fr:  0.16874349\n",
      "epoch:  5 . Loss:  0.5352290272712708 . Tr Accuracy:  87.37696850393701 . Ts Accuracy:  67.1875 Fr:  0.16528125\n",
      "epoch:  6 . Loss:  0.29107001423835754 . Tr Accuracy:  90.45275590551181 . Ts Accuracy:  76.16071428571429 Fr:  0.17019661\n",
      "epoch:  7 . Loss:  0.37120315432548523 . Tr Accuracy:  91.57234251968504 . Ts Accuracy:  72.8125 Fr:  0.16496615\n",
      "epoch:  8 . Loss:  0.12378918379545212 . Tr Accuracy:  93.29478346456693 . Ts Accuracy:  74.95535714285714 Fr:  0.17080729\n",
      "epoch:  9 . Loss:  0.2088315635919571 . Tr Accuracy:  93.95915354330708 . Ts Accuracy:  76.16071428571429 Fr:  0.16975391\n",
      "epoch:  10 . Loss:  0.4096953570842743 . Tr Accuracy:  94.35285433070867 . Ts Accuracy:  73.39285714285714 Fr:  0.170875\n",
      "epoch:  11 . Loss:  0.03052808903157711 . Tr Accuracy:  96.80118110236221 . Ts Accuracy:  79.77678571428571 Fr:  0.16770183\n",
      "epoch:  12 . Loss:  0.04647911712527275 . Tr Accuracy:  97.14566929133858 . Ts Accuracy:  79.77678571428571 Fr:  0.17166796\n",
      "epoch:  13 . Loss:  0.061607349663972855 . Tr Accuracy:  97.33021653543307 . Ts Accuracy:  80.80357142857143 Fr:  0.16823567\n",
      "epoch:  14 . Loss:  0.10661520063877106 . Tr Accuracy:  97.49015748031496 . Ts Accuracy:  76.33928571428571 Fr:  0.17013672\n",
      "epoch:  15 . Loss:  0.1564086526632309 . Tr Accuracy:  97.20718503937007 . Ts Accuracy:  77.27678571428571 Fr:  0.17280209\n",
      "epoch:  16 . Loss:  0.14530357718467712 . Tr Accuracy:  97.33021653543307 . Ts Accuracy:  75.58035714285714 Fr:  0.17416276\n",
      "epoch:  17 . Loss:  0.023921921849250793 . Tr Accuracy:  97.30561023622047 . Ts Accuracy:  79.01785714285714 Fr:  0.16811068\n",
      "epoch:  18 . Loss:  0.05970204994082451 . Tr Accuracy:  97.79773622047244 . Ts Accuracy:  75.75892857142857 Fr:  0.16774088\n",
      "epoch:  19 . Loss:  0.06563874334096909 . Tr Accuracy:  97.87155511811024 . Ts Accuracy:  79.46428571428571 Fr:  0.17141797\n",
      "Mean FR:  0.17170182\n",
      " Accuracy:  79.33035714285714\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [48,48]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c8af1f-5faf-47f2-9767-56e2e566abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  2.2305121421813965 . Tr Accuracy:  11.700295275590552 . Ts Accuracy:  23.571428571428573 Fr:  0.20851563\n",
      "epoch:  2 . Loss:  1.247761845588684 . Tr Accuracy:  38.45964566929134 . Ts Accuracy:  45.580357142857146 Fr:  0.18563086\n",
      "epoch:  3 . Loss:  1.0206964015960693 . Tr Accuracy:  59.30118110236221 . Ts Accuracy:  64.41964285714286 Fr:  0.1778418\n",
      "epoch:  4 . Loss:  0.8707325458526611 . Tr Accuracy:  71.56742125984252 . Ts Accuracy:  70.71428571428571 Fr:  0.18417577\n",
      "epoch:  5 . Loss:  0.3953717052936554 . Tr Accuracy:  77.79281496062993 . Ts Accuracy:  67.41071428571429 Fr:  0.18475977\n",
      "epoch:  6 . Loss:  0.48988014459609985 . Tr Accuracy:  83.30462598425197 . Ts Accuracy:  68.97321428571429 Fr:  0.18675\n",
      "epoch:  7 . Loss:  0.415967732667923 . Tr Accuracy:  85.35925196850394 . Ts Accuracy:  70.625 Fr:  0.1925918\n",
      "epoch:  8 . Loss:  0.345842182636261 . Tr Accuracy:  87.80757874015748 . Ts Accuracy:  75.625 Fr:  0.19554493\n",
      "epoch:  9 . Loss:  0.27550792694091797 . Tr Accuracy:  89.94832677165354 . Ts Accuracy:  76.38392857142857 Fr:  0.19525196\n",
      "epoch:  10 . Loss:  0.30948811769485474 . Tr Accuracy:  90.55118110236221 . Ts Accuracy:  75.49107142857143 Fr:  0.19035937\n",
      "epoch:  11 . Loss:  0.18383775651454926 . Tr Accuracy:  93.8115157480315 . Ts Accuracy:  77.72321428571429 Fr:  0.19154102\n",
      "epoch:  12 . Loss:  0.14766617119312286 . Tr Accuracy:  94.21751968503936 . Ts Accuracy:  78.61607142857143 Fr:  0.19146875\n",
      "epoch:  13 . Loss:  0.16078545153141022 . Tr Accuracy:  94.46358267716535 . Ts Accuracy:  76.96428571428571 Fr:  0.19735156\n",
      "epoch:  14 . Loss:  0.10109958052635193 . Tr Accuracy:  94.45127952755905 . Ts Accuracy:  77.94642857142857 Fr:  0.19091602\n",
      "epoch:  15 . Loss:  0.23690739274024963 . Tr Accuracy:  95.14025590551181 . Ts Accuracy:  73.66071428571429 Fr:  0.19665626\n",
      "epoch:  16 . Loss:  0.28389206528663635 . Tr Accuracy:  94.78346456692914 . Ts Accuracy:  77.1875 Fr:  0.1954668\n",
      "epoch:  17 . Loss:  0.07262362539768219 . Tr Accuracy:  94.88188976377953 . Ts Accuracy:  79.50892857142857 Fr:  0.19226368\n",
      "epoch:  18 . Loss:  0.118636853992939 . Tr Accuracy:  95.38631889763779 . Ts Accuracy:  78.39285714285714 Fr:  0.19242384\n",
      "epoch:  19 . Loss:  0.13951659202575684 . Tr Accuracy:  95.98917322834646 . Ts Accuracy:  78.57142857142857 Fr:  0.19642188\n",
      "Mean FR:  0.19434765\n",
      " Accuracy:  78.70535714285714\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [32,32]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59305f7c-f492-4b25-9193-033f548b2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.8285083770751953 . Tr Accuracy:  25.93503937007874 . Ts Accuracy:  47.99107142857143 Fr:  0.14043806\n",
      "epoch:  2 . Loss:  0.5858820676803589 . Tr Accuracy:  66.43700787401575 . Ts Accuracy:  75.44642857142857 Fr:  0.14046875\n",
      "epoch:  3 . Loss:  0.2967982888221741 . Tr Accuracy:  83.13238188976378 . Ts Accuracy:  74.33035714285714 Fr:  0.13985212\n",
      "epoch:  4 . Loss:  0.29008811712265015 . Tr Accuracy:  87.73375984251969 . Ts Accuracy:  78.57142857142857 Fr:  0.13194476\n",
      "epoch:  5 . Loss:  0.20904408395290375 . Tr Accuracy:  90.41584645669292 . Ts Accuracy:  82.54464285714286 Fr:  0.13089676\n",
      "epoch:  6 . Loss:  0.12574677169322968 . Tr Accuracy:  92.51968503937007 . Ts Accuracy:  78.97321428571429 Fr:  0.12667857\n",
      "epoch:  7 . Loss:  0.2575814723968506 . Tr Accuracy:  94.52509842519684 . Ts Accuracy:  86.78571428571429 Fr:  0.1280731\n",
      "epoch:  8 . Loss:  0.18737050890922546 . Tr Accuracy:  94.73425196850394 . Ts Accuracy:  80.80357142857143 Fr:  0.12865067\n",
      "epoch:  9 . Loss:  0.08199994266033173 . Tr Accuracy:  94.88188976377953 . Ts Accuracy:  86.78571428571429 Fr:  0.1316211\n",
      "epoch:  10 . Loss:  0.3276408910751343 . Tr Accuracy:  95.2755905511811 . Ts Accuracy:  78.79464285714286 Fr:  0.1274163\n",
      "epoch:  11 . Loss:  0.03805533051490784 . Tr Accuracy:  97.85925196850394 . Ts Accuracy:  83.21428571428571 Fr:  0.12740792\n",
      "epoch:  12 . Loss:  0.09369104355573654 . Tr Accuracy:  98.5974409448819 . Ts Accuracy:  84.46428571428571 Fr:  0.12770313\n",
      "epoch:  13 . Loss:  0.05827349051833153 . Tr Accuracy:  98.63435039370079 . Ts Accuracy:  86.60714285714286 Fr:  0.1266423\n",
      "epoch:  14 . Loss:  0.03683413937687874 . Tr Accuracy:  98.3759842519685 . Ts Accuracy:  86.47321428571429 Fr:  0.12923159\n",
      "epoch:  15 . Loss:  0.04819782078266144 . Tr Accuracy:  98.69586614173228 . Ts Accuracy:  84.50892857142857 Fr:  0.1254799\n",
      "epoch:  16 . Loss:  0.0777975395321846 . Tr Accuracy:  98.4990157480315 . Ts Accuracy:  85.89285714285714 Fr:  0.12944698\n",
      "epoch:  17 . Loss:  0.03637116402387619 . Tr Accuracy:  98.73277559055119 . Ts Accuracy:  85.71428571428571 Fr:  0.13335045\n",
      "epoch:  18 . Loss:  0.04581193998456001 . Tr Accuracy:  98.4990157480315 . Ts Accuracy:  83.16964285714286 Fr:  0.12558761\n",
      "epoch:  19 . Loss:  0.02690461091697216 . Tr Accuracy:  98.4251968503937 . Ts Accuracy:  82.85714285714286 Fr:  0.12814453\n",
      "Mean FR:  0.1263722\n",
      " Accuracy:  82.99107142857143\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [112,112]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19535975-84cb-483a-987f-ced9a51780a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.6252371072769165 . Tr Accuracy:  21.838090551181104 . Ts Accuracy:  40.669642857142854 Fr:  0.1609069\n",
      "epoch:  2 . Loss:  1.2593910694122314 . Tr Accuracy:  52.09153543307087 . Ts Accuracy:  57.36607142857143 Fr:  0.15891472\n",
      "epoch:  3 . Loss:  1.0506930351257324 . Tr Accuracy:  67.67962598425197 . Ts Accuracy:  65.3125 Fr:  0.15386589\n",
      "epoch:  4 . Loss:  0.4382389783859253 . Tr Accuracy:  76.63631889763779 . Ts Accuracy:  71.91964285714286 Fr:  0.1525651\n",
      "epoch:  5 . Loss:  0.34050437808036804 . Tr Accuracy:  82.9109251968504 . Ts Accuracy:  76.60714285714286 Fr:  0.14895703\n",
      "epoch:  6 . Loss:  0.6541894674301147 . Tr Accuracy:  85.80216535433071 . Ts Accuracy:  73.25892857142857 Fr:  0.15017448\n",
      "epoch:  7 . Loss:  0.502514660358429 . Tr Accuracy:  88.85334645669292 . Ts Accuracy:  75.49107142857143 Fr:  0.14427409\n",
      "epoch:  8 . Loss:  0.2159011960029602 . Tr Accuracy:  90.69881889763779 . Ts Accuracy:  79.59821428571429 Fr:  0.1401263\n",
      "epoch:  9 . Loss:  0.1294175386428833 . Tr Accuracy:  91.37549212598425 . Ts Accuracy:  79.41964285714286 Fr:  0.13772982\n",
      "epoch:  10 . Loss:  0.2508927881717682 . Tr Accuracy:  92.1259842519685 . Ts Accuracy:  77.72321428571429 Fr:  0.13742904\n",
      "epoch:  11 . Loss:  0.3083532452583313 . Tr Accuracy:  94.75885826771653 . Ts Accuracy:  82.45535714285714 Fr:  0.13563998\n",
      "epoch:  12 . Loss:  0.11481385678052902 . Tr Accuracy:  96.08759842519684 . Ts Accuracy:  78.66071428571429 Fr:  0.13317838\n",
      "epoch:  13 . Loss:  0.12930986285209656 . Tr Accuracy:  96.25984251968504 . Ts Accuracy:  81.91964285714286 Fr:  0.1341608\n",
      "epoch:  14 . Loss:  0.16246230900287628 . Tr Accuracy:  96.53051181102362 . Ts Accuracy:  82.54464285714286 Fr:  0.13795573\n",
      "epoch:  15 . Loss:  0.04449426010251045 . Tr Accuracy:  96.34596456692914 . Ts Accuracy:  79.77678571428571 Fr:  0.13272981\n",
      "epoch:  16 . Loss:  0.09122465550899506 . Tr Accuracy:  96.51820866141732 . Ts Accuracy:  77.54464285714286 Fr:  0.13385026\n",
      "epoch:  17 . Loss:  0.3243388235569 . Tr Accuracy:  96.7642716535433 . Ts Accuracy:  77.85714285714286 Fr:  0.13221355\n",
      "epoch:  18 . Loss:  0.13514265418052673 . Tr Accuracy:  97.02263779527559 . Ts Accuracy:  82.90178571428571 Fr:  0.13239844\n",
      "epoch:  19 . Loss:  0.08244969695806503 . Tr Accuracy:  96.89960629921259 . Ts Accuracy:  82.41071428571429 Fr:  0.13363217\n",
      "Mean FR:  0.13259245\n",
      " Accuracy:  81.42857142857143\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [96,96]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223e47dd-56fc-4f1d-a0a2-a300fd9994dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "epoch:  1 . Loss:  1.5336837768554688 . Tr Accuracy:  23.351377952755904 . Ts Accuracy:  47.36607142857143 Fr:  0.14830548\n",
      "epoch:  2 . Loss:  1.0515326261520386 . Tr Accuracy:  62.463090551181104 . Ts Accuracy:  68.25892857142857 Fr:  0.13543594\n",
      "epoch:  3 . Loss:  0.6928795576095581 . Tr Accuracy:  75.1599409448819 . Ts Accuracy:  79.55357142857143 Fr:  0.13739297\n",
      "epoch:  4 . Loss:  0.44312426447868347 . Tr Accuracy:  84.81791338582677 . Ts Accuracy:  80.3125 Fr:  0.14193438\n",
      "epoch:  5 . Loss:  0.2593187093734741 . Tr Accuracy:  89.24704724409449 . Ts Accuracy:  80.71428571428571 Fr:  0.1414875\n",
      "epoch:  6 . Loss:  0.2453763782978058 . Tr Accuracy:  90.87106299212599 . Ts Accuracy:  82.27678571428571 Fr:  0.14467968\n",
      "epoch:  7 . Loss:  0.26052993535995483 . Tr Accuracy:  91.97834645669292 . Ts Accuracy:  79.6875 Fr:  0.13881172\n",
      "epoch:  8 . Loss:  0.13671623170375824 . Tr Accuracy:  93.17175196850394 . Ts Accuracy:  82.58928571428571 Fr:  0.13888046\n",
      "epoch:  9 . Loss:  0.2089717537164688 . Tr Accuracy:  93.45472440944881 . Ts Accuracy:  78.30357142857143 Fr:  0.135325\n",
      "epoch:  10 . Loss:  0.15848538279533386 . Tr Accuracy:  93.87303149606299 . Ts Accuracy:  80.0 Fr:  0.14079766\n",
      "epoch:  11 . Loss:  0.05191587656736374 . Tr Accuracy:  97.62549212598425 . Ts Accuracy:  83.88392857142857 Fr:  0.14000937\n",
      "epoch:  12 . Loss:  0.10186506062746048 . Tr Accuracy:  98.30216535433071 . Ts Accuracy:  82.90178571428571 Fr:  0.14153203\n",
      "epoch:  13 . Loss:  0.0231334138661623 . Tr Accuracy:  98.17913385826772 . Ts Accuracy:  84.33035714285714 Fr:  0.14237109\n",
      "epoch:  14 . Loss:  0.04592372477054596 . Tr Accuracy:  98.4744094488189 . Ts Accuracy:  81.29464285714286 Fr:  0.14206953\n",
      "epoch:  15 . Loss:  0.10913316905498505 . Tr Accuracy:  98.4005905511811 . Ts Accuracy:  80.80357142857143 Fr:  0.14263828\n",
      "epoch:  16 . Loss:  0.06520528346300125 . Tr Accuracy:  98.4867125984252 . Ts Accuracy:  82.58928571428571 Fr:  0.14349923\n",
      "epoch:  17 . Loss:  0.05644168332219124 . Tr Accuracy:  98.09301181102362 . Ts Accuracy:  82.09821428571429 Fr:  0.13989219\n",
      "epoch:  18 . Loss:  0.07382920384407043 . Tr Accuracy:  98.4005905511811 . Ts Accuracy:  79.59821428571429 Fr:  0.1362336\n",
      "epoch:  19 . Loss:  0.006082051433622837 . Tr Accuracy:  99.08956692913385 . Ts Accuracy:  83.25892857142857 Fr:  0.142775\n",
      "Mean FR:  0.15043437\n",
      " Accuracy:  83.16964285714286\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 700\n",
    "hidden_dim = [80,80]  # 128\n",
    "output_dim = 20\n",
    "seq_dim = 250  # Number of steps to unroll\n",
    "num_encode = 700\n",
    "total_steps = seq_dim\n",
    "\n",
    "model = RNN_custom(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate =  1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-5)\n",
    "\n",
    "# base_params = [model.i_2_h1.weight, model.i_2_h1.bias,\n",
    "#                model.h1_2_h1.weight, model.h1_2_h1.bias,\n",
    "#                model.h1_2_h2.weight, model.h1_2_h2.bias,\n",
    "#                model.h2_2_h2.weight, model.h2_2_h2.bias,\n",
    "#                model.h2o.weight, model.h2o.bias]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': model.tau_adp_h1, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_adp_h2, 'lr': learning_rate * 5},\n",
    "#     {'params': model.tau_m_h1, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_h2, 'lr': learning_rate * 1},\n",
    "#     {'params': model.tau_m_o, 'lr': learning_rate * 1}],\n",
    "#     lr=learning_rate,eps=1e-5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=.5)\n",
    "\n",
    "path = os.path.join(CHECKPOINT_PATH,'bojian_model')  # .pth'\n",
    "\n",
    "acc = train(model, num_epochs)\n",
    "test_acc,fr = test(model,is_test=1)\n",
    "print(' Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b2826-b172-48f4-8fb0-7f4b9a15486f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
